# nithurshen-langgraph-MAT496
This repository documents my learning from the LangChain Academy's "Intro to LangGraph" course. Each commit corresponds to a specific video lesson and features personalized modifications to the original source code. The README file serves as a detailed log, containing a summary of key concepts from each video and notes on my code tweaks.

<b>Name:</b> K S Nithurshen  
<b>Roll No:</b> 2410110157  

## Module 0:
I've learned the fundamentals of setting up a LangChain environment and interacting with its core components. The course covered how to instantiate different ChatOpenAI models, like gpt-4o and gpt-3.5-turbo, and how to use the .invoke() method to send prompts. It also introduced the integration of external search tools, specifically using TavilySearchResults. I've put these concepts into practice in my own notebook by experimenting with other models like gpt-4.1-nano and gpt-4o-mini. To align the exercise with my interest in Formula 1, I modified the tool run by changing the TavilySearchResults query to "Who is Max Verstappen?" and increased the max_results parameter to 50 for a more extensive search. (https://github.com/Nithurshen/nithurshen-langgraph-MAT496/blob/main/module-0/my_example_of_basics.ipynb)

## Module 1: (Introduction)
* <b>Lesson 1:</b> I've learned about the fundamental trade-off in building LLM applications between the reliability of fixed, linear "chains" and the agency or flexibility of "agents". While chains are dependable because they execute the same control flow every time, they are limited. Agents are more powerful because they use an LLM to decide their own control flow, but this makes them less predictable. LangGraph is presented as the solution to this problem, designed to optimize the curve by enabling developers to build applications as graphs. This graph-based approach allows for a balance of reliability and control by letting the developer define the structure while injecting an LLM at specific points to make routing decisions. These graphs operate on a shared state or memory, and nodes can call tools to modify that state, providing a robust framework for creating more dependable and controllable agents.
* <b>Lesson 2:</b> Based on this lesson, I've learned how to build a simple application using LangGraph's core components. The process starts with defining a State using a TypedDict, which acts as a shared memory schema for the entire graph. I then created Nodes, which are Python functions that take this state as an argument and return a dictionary to update it. The key to creating dynamic workflows is using Conditional Edges, which are functions that route the execution to different nodes based on the current state. I put this into practice by building a more complex, F1-themed graph than the one in the lesson. My implementation uses eight nodes and three separate conditional edges to randomly generate a sentence about a race, deciding on the driver (e.g., Max Verstappen or Sebastian Vettel), the outcome (won or lost), and the specific event (Monaco GP or Le Mans). Finally, I compiled the graph and successfully used the .invoke() method to run it, confirming my understanding of how to construct and execute a stateful, branching workflow.
