{
 "cells": [
  {
   "cell_type": "code",
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:41.131850Z",
     "start_time": "2025-10-23T04:09:41.127381Z"
    }
   },
   "source": [
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:41.964635Z",
     "start_time": "2025-10-23T04:09:41.141911Z"
    }
   },
   "source": [
    "from typing import Literal\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, RemoveMessage, AIMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "\n",
    "class RaceSessionState(MessagesState):\n",
    "    race_summary: str\n",
    "\n",
    "def call_race_control(state: RaceSessionState, config: RunnableConfig):\n",
    "    summary = state.get(\"race_summary\", \"\")\n",
    "    if summary:\n",
    "        system_message = f\"Summary of the race session so far: {summary}\"\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def generate_race_report(state: RaceSessionState):\n",
    "    summary = state.get(\"race_summary\", \"\")\n",
    "    if summary:\n",
    "        summary_message = (\n",
    "            f\"This is the race report so far: {summary}\\n\\n\"\n",
    "            \"Update the report based on the new radio messages above:\"\n",
    "        )\n",
    "    else:\n",
    "        summary_message = \"Generate a brief race report based on the radio messages above:\"\n",
    "\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"race_summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "def should_generate_report(state: RaceSessionState) -> Literal[\"generate_race_report\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 6:\n",
    "        return \"generate_race_report\"\n",
    "    return END\n",
    "\n",
    "workflow = StateGraph(RaceSessionState)\n",
    "workflow.add_node(\"radio_comms\", call_race_control)\n",
    "workflow.add_node(generate_race_report)\n",
    "\n",
    "workflow.add_edge(START, \"radio_comms\")\n",
    "workflow.add_conditional_edges(\"radio_comms\", should_generate_report)\n",
    "workflow.add_edge(\"generate_race_report\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:44.699435Z",
     "start_time": "2025-10-23T04:09:41.976632Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"f1_stream_updates\"}}\n",
    "\n",
    "input_message = HumanMessage(content=\"Box this lap.\", name=\"RaceEngineer\")\n",
    "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'radio_comms': {'messages': AIMessage(content='Copy that. Box this lap and prepare for a pit stop.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 14, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_950f36939b', 'id': 'chatcmpl-CTgvvsgaT7tfh7Nhk0iIqJj3DwgWH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--77c9c2bf-e2d5-431a-b248-87c1a7348c83-0', usage_metadata={'input_tokens': 14, 'output_tokens': 13, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:45.593932Z",
     "start_time": "2025-10-23T04:09:44.702865Z"
    }
   },
   "source": [
    "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    if \"radio_comms\" in chunk:\n",
    "        chunk['radio_comms'][\"messages\"].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Understood. Box this lap and prepare for a pit stop.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:46.394559Z",
     "start_time": "2025-10-23T04:09:45.597306Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"f1_stream_values\"}}\n",
    "\n",
    "input_message = HumanMessage(content=\"Confirm strategy.\", name=\"Driver_VER\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "Name: Driver_VER\n",
      "\n",
      "Confirm strategy.\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "Name: Driver_VER\n",
      "\n",
      "Confirm strategy.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hello! Could you please provide more details about the strategy you'd like to confirm? This will help me assist you more effectively.\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:47.327103Z",
     "start_time": "2025-10-23T04:09:46.399981Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"f1_astream_events\"}}\n",
    "input_message = HumanMessage(content=\"What's the gap to Hamilton?\", name=\"Driver_LEC\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: radio_comms. Type: on_chain_start. Name: radio_comms\n",
      "Node: radio_comms. Type: on_chat_model_start. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chat_model_end. Name: ChatOpenAI\n",
      "Node: radio_comms. Type: on_chain_start. Name: should_generate_report\n",
      "Node: radio_comms. Type: on_chain_end. Name: should_generate_report\n",
      "Node: radio_comms. Type: on_chain_stream. Name: radio_comms\n",
      "Node: radio_comms. Type: on_chain_end. Name: radio_comms\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:50.264016Z",
     "start_time": "2025-10-23T04:09:48.497428Z"
    }
   },
   "source": [
    "node_to_stream = 'radio_comms'\n",
    "config = {\"configurable\": {\"thread_id\": \"f1_token_stream\"}}\n",
    "input_message = HumanMessage(content=\"Push now, push now!\", name=\"RaceEngineer\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content='It', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' sounds', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' like', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=\" you're\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' encouraging', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' someone', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' give', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' best', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' effort', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content='â€”', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content='great', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' motivation', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' If', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=\" you're\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' referring', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' race', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' engineer', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' keep', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' pushing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' forward', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' stay', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' focused', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' Let', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' me', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' know', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' if', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=\" you'd\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' like', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' any', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' specific', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' advice', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' support', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' related', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' racing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' strategies', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content=' engineering', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_950f36939b', 'service_tier': 'default', 'model_provider': 'openai'}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef', chunk_position='last')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef', usage_metadata={'input_tokens': 16, 'output_tokens': 51, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--a7b6756b-3630-46e0-a573-0d2abcfecaef', chunk_position='last')}\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:50.777241Z",
     "start_time": "2025-10-23T04:09:50.269806Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"f1_token_stream_print\"}}\n",
    "input_message = HumanMessage(content=\"Copy that.\", name=\"Driver_NOR\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Under|stood|.| How| can| I| assist| you| further|?||||"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:50.789618Z",
     "start_time": "2025-10-23T04:09:50.787608Z"
    }
   },
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "079c2ad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:50.806950Z",
     "start_time": "2025-10-23T04:09:50.795815Z"
    }
   },
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:57.580493Z",
     "start_time": "2025-10-23T04:09:50.811777Z"
    }
   },
   "source": [
    "# Assuming 'f1_race_data' is the assistant_id corresponding to your graph\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"What tyre compound is Perez on?\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"],\n",
    "                                      assistant_id=\"f1_race_data\",\n",
    "                                      input={\"messages\": [input_message]},\n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '019a0f42-3de0-77ab-825b-0a25819d12b1', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'What tyre compound is Perez on?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'dfd08518-88fb-4ec8-a524-a4ccf4c1d3db'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'What tyre compound is Perez on?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'dfd08518-88fb-4ec8-a524-a4ccf4c1d3db'}, {'content': \"I'm sorry, but I don't have real-time data or the ability to access current events or live updates. To find out what tyre compound Sergio Perez is using, you would need to check a live broadcast of the race, a sports news website, or the official Formula 1 app or website for the most up-to-date information.\", 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 66, 'prompt_tokens': 14, 'total_tokens': 80, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a788c5aef0', 'id': 'chatcmpl-CTgw3zcIPxLGRmPXzwCyLTvyGI6R9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'lc_run--f4657169-d94c-4d57-a553-bc21edace037-0', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 14, 'output_tokens': 66, 'total_tokens': 80, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:09:59.581812Z",
     "start_time": "2025-10-23T04:09:57.587344Z"
    }
   },
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Is rain expected in 10 laps?\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"f1_race_data\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Is rain expected in 10 laps?' additional_kwargs={} response_metadata={} id='7075c32a-69bd-4f67-a1a4-661f243c1f0c'\n",
      "=========================\n",
      "content=\"I'm sorry, but I can't provide real-time weather updates or forecasts. To get the most accurate and up-to-date weather information, I recommend checking a reliable weather service or app.\" additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 15, 'output_tokens': 36, 'total_tokens': 51, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 15, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CTgwAuDuU6u2LiXNYB0nSeg4tWDiQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--d55f48b2-65e5-4d8f-838b-a0502d555ddd-0'\n",
      "=========================\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:10:03.653115Z",
     "start_time": "2025-10-23T04:09:59.586745Z"
    }
   },
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Update on track limits for Turn 4.\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"],\n",
    "                                      assistant_id=\"f1_race_data\",\n",
    "                                      input={\"messages\": [input_message]},\n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:10:05.879990Z",
     "start_time": "2025-10-23T04:10:03.659961Z"
    }
   },
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Plan B? Confirm Plan B.\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"f1_race_data\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Input: {data_item['content']}\")\n",
    "            else:\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"Response: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    elif event.event == \"messages/complete\":\n",
    "        pass"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 019a0f42-7013-749e-81ee-5fc4e6a59302\n",
      "--------------------------------------------------\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\"\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to?\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context,\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan,\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product,\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy.\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know so\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know so I\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know so I can\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know so I can assist\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know so I can assist you\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know so I can assist you better\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know so I can assist you better!\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know so I can assist you better!\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know so I can assist you better!\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n",
      "Response: Could you please provide more context or specify what \"Plan B\" refers to? It could mean different things depending on the context, such as a backup plan, a specific product, or a particular strategy. Let me know so I can assist you better!\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 46
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
